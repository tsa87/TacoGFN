{
   "cells": [
      {
         "cell_type": "code",
         "execution_count": 27,
         "metadata": {},
         "outputs": [],
         "source": [
            "import sys\n",
            "import torch\n",
            "\n",
            "sys.path.append('../')"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 28,
         "metadata": {},
         "outputs": [],
         "source": [
            "from src.tacogfn.tasks import pharmaco_frag"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 33,
         "metadata": {},
         "outputs": [],
         "source": [
            "hps = {\n",
            "    \"log_dir\": \"./logs/debug_run_pharmaco_frag_pb\",\n",
            "    \"split_file\": '../dataset/split_by_name.pt',\n",
            "    \"pharmacophore_db_path\": '../misc/pharmacophores_db.lmdb',\n",
            "    'affinity_predictor_path': \"../logs/debug_docking_score_prediction_beta/model_state_23.pt\",\n",
            "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
            "    \"overwrite_existing_exp\": True,\n",
            "    \"num_training_steps\": 10_000,\n",
            "    \"num_workers\": 1,\n",
            "    \"opt\": {\n",
            "        \"lr_decay\": 20000,\n",
            "    },\n",
            "    \"algo\": {\"sampling_tau\": 0.99, \"offline_ratio\": 0.0},\n",
            "    \"cond\": {\n",
            "        \"temperature\": {\n",
            "            \"sample_dist\": \"uniform\",\n",
            "            \"dist_params\": [0, 64.0],\n",
            "        }\n",
            "    },\n",
            "}"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 34,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "loaded 15016 ids for train\n",
                  "loaded 100 ids for test\n",
                  "\n",
                  "\n",
                  "Hyperparameters:\n",
                  "\n",
                  "log_dir: ./logs/debug_run_pharmaco_frag_pb\n",
                  "device: cuda\n",
                  "split_file: ../dataset/split_by_name.pt\n",
                  "pharmacophore_db_path: ../misc/pharmacophores_db.lmdb\n",
                  "affinity_predictor_path: ../logs/debug_docking_score_prediction_beta/model_state_23.pt\n",
                  "seed: 0\n",
                  "validate_every: 1000\n",
                  "checkpoint_every: null\n",
                  "print_every: 100\n",
                  "start_at_step: 0\n",
                  "num_final_gen_steps: null\n",
                  "num_training_steps: 10000\n",
                  "num_workers: 1\n",
                  "hostname: DESKTOP-2DNJF9F\n",
                  "pickle_mp_messages: false\n",
                  "git_hash: 6ae029a\n",
                  "overwrite_existing_exp: true\n",
                  "algo:\n",
                  "  method: TB\n",
                  "  global_batch_size: 64\n",
                  "  max_len: 128\n",
                  "  max_nodes: 9\n",
                  "  max_edges: 128\n",
                  "  illegal_action_logreward: -75.0\n",
                  "  offline_ratio: 0.0\n",
                  "  valid_offline_ratio: 0.0\n",
                  "  train_random_action_prob: 0.01\n",
                  "  valid_random_action_prob: 0.0\n",
                  "  valid_sample_cond_info: true\n",
                  "  sampling_tau: 0.99\n",
                  "  tb:\n",
                  "    bootstrap_own_reward: false\n",
                  "    epsilon: null\n",
                  "    reward_loss_multiplier: 1.0\n",
                  "    variant: TB\n",
                  "    do_correct_idempotent: false\n",
                  "    do_parameterize_p_b: false\n",
                  "    do_sample_p_b: true\n",
                  "    do_length_normalize: false\n",
                  "    subtb_max_len: 128\n",
                  "    Z_learning_rate: 0.001\n",
                  "    Z_lr_decay: 50000.0\n",
                  "    cum_subtb: true\n",
                  "model:\n",
                  "  num_layers: 4\n",
                  "  num_emb: 128\n",
                  "  dropout: 0.0\n",
                  "  graph_transformer:\n",
                  "    num_heads: 2\n",
                  "    ln_type: pre\n",
                  "    num_mlp_layers: 0\n",
                  "  pharmaco_cond:\n",
                  "    pharmaco_dim: 64\n",
                  "opt:\n",
                  "  opt: adam\n",
                  "  learning_rate: 0.0001\n",
                  "  lr_decay: 20000.0\n",
                  "  weight_decay: 1.0e-08\n",
                  "  momentum: 0.9\n",
                  "  clip_grad_type: norm\n",
                  "  clip_grad_param: 10.0\n",
                  "  adam_eps: 1.0e-08\n",
                  "replay:\n",
                  "  use: false\n",
                  "  capacity: 10000\n",
                  "  warmup: 1000\n",
                  "  hindsight_ratio: 0.0\n",
                  "task:\n",
                  "  seh: {}\n",
                  "  seh_moo:\n",
                  "    use_steer_thermometer: false\n",
                  "    preference_type: dirichlet\n",
                  "    focus_type: null\n",
                  "    focus_dirs_listed: null\n",
                  "    focus_cosim: 0.0\n",
                  "    focus_limit_coef: 1.0\n",
                  "    focus_model_training_limits: null\n",
                  "    focus_model_state_space_res: null\n",
                  "    max_train_it: null\n",
                  "    n_valid: 15\n",
                  "    n_valid_repeats: 128\n",
                  "    objectives:\n",
                  "    - seh\n",
                  "    - qed\n",
                  "    - sa\n",
                  "    - mw\n",
                  "  pharmaco_frag:\n",
                  "    fragment_type: gflownet\n",
                  "    affinity_predictor: beta\n",
                  "    min_docking_score: -5.0\n",
                  "cond:\n",
                  "  temperature:\n",
                  "    sample_dist: uniform\n",
                  "    dist_params:\n",
                  "    - 0\n",
                  "    - 64.0\n",
                  "    num_thermometer_dim: 32\n",
                  "  moo:\n",
                  "    num_objectives: 2\n",
                  "    num_thermometer_dim: 16\n",
                  "  weighted_prefs:\n",
                  "    preference_type: dirichlet\n",
                  "  focus_region:\n",
                  "    focus_type: learned-tabular\n",
                  "    use_steer_thermomether: false\n",
                  "    focus_cosim: 0.98\n",
                  "    focus_limit_coef: 0.1\n",
                  "    focus_model_training_limits:\n",
                  "    - 0.25\n",
                  "    - 0.75\n",
                  "    focus_model_state_space_res: 30\n",
                  "    max_train_it: 20000\n",
                  "\n"
               ]
            }
         ],
         "source": [
            "trainer = pharmaco_frag.PharmacophoreTrainer(hps)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 35,
         "metadata": {},
         "outputs": [],
         "source": [
            "split_file = torch.load('../dataset/split_by_name.pt')\n",
            "tuple_to_pharmaco_id = lambda t: t[0].split(\"/\")[-1].split(\"_rec\")[0]\n",
            "\n",
            "train_ids = [tuple_to_pharmaco_id(t) for t in split_file[\"train\"]]\n",
            "test_ids = [tuple_to_pharmaco_id(t) for t in split_file[\"test\"]]"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 36,
         "metadata": {},
         "outputs": [],
         "source": [
            "for i in test_ids:\n",
            "    if i not in trainer.pharmaco_db.all_id:\n",
            "        print(f\"Missing {i} in pharmacophore db\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 6,
         "metadata": {},
         "outputs": [],
         "source": [
            "trainer.print_every = 1"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 1,
         "metadata": {},
         "outputs": [],
         "source": [
            "# trainer.run()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": []
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": "tacogfn",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.9.18"
      }
   },
   "nbformat": 4,
   "nbformat_minor": 2
}
